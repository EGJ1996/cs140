       	       	    +---------------------------+
                    +---------------------------+
                    |           CS 140          |
                    | PROJECT 3: VIRTUAL MEMORY |
                    |      DESIGN DOCUMENT      |
                    +---------------------------+
---- GROUP ----
>> Fill in the names and email addresses of your group members.

Naftali Harris <naftali@stanford.edu>
Luke Pappas <lpappas9@stanford.edu>
Connor Woodson <cwoodson@stanford.edu>

---- PRELIMINARIES ----
>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.


                        PAGE TABLE MANAGEMENT
                        =====================
---- DATA STRUCTURES ----
>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* The different types of pages */
typedef enum {
    SWAP_PAGE,
    FILE_PAGE,
    MMAPED_PAGE,
} page_location;

Purpose: allows us to track where a page will be paged out to.
====================================================================
/*
 --------------------------------------------------------------------
 DESCRIPTION: tracks the additional info we need to keep tabs on
for a page.
 NOTE: location indicates where to access page if not in physical
    memory
 NOTE: page_id is how we identify pages. It is the equivalent of
    calling round down on a virtual address.
 NOTE: the pinned filed is used for page eviction. If a page
    is pinned, it cannot be evicted.
 --------------------------------------------------------------------
 */
struct spte
{
    struct hash_elem elem; /* For the per-process list                   */
    struct lock page_lock;
    page_location location;
    struct thread* owner_thread; /* needed to access pd */
    void* page_id;
    struct frame* frame; /* the physical frame of the page if it is memory */
    bool is_writeable;   /*true if the page can be written to */
    bool is_loaded;      /*true if the page is currently loaded in memory */
    struct file* file_ptr;
    off_t offset_in_file;
    uint32_t read_bytes;
    uint32_t zero_bytes;
    uint32_t swap_index; /* index into the swap sector */
};

Purpose: tracks additional info about a page. See comments.

====================================================================
/*
 --------------------------------------------------------------------
 DESCRIPTION: The struct containing information to manage
    a frame of physical memory
 NOTE: Resident_page is a pointer to the spte for the page
    that currently occupies a frame.
 NOTE: frame_base is the pointer that is returned by a call
    to palloc. It is the base address for a page of physical
    memory.
 NOTE: frame_lock locks the given frame for sycnchronization
    purposes
 --------------------------------------------------------------------
 */

struct frame {
    struct spte* resident_page;

    void* physical_mem_frame_base;
    struct lock frame_lock;
};

Purpose: allows us to track usage information for a frame of
        physical memory

====================================================================

/* Globals */
static struct frame* frame_table; //our frame table
static size_t total_frames; //the total number of frames, set at pintos launch
static void* first_frame; //head of our table, used for initialization
struct lock frame_evict_lock; //see synchronization comments in design doc for
purpose
static uint32_t clock_hand = 0; //the index into frame table of next frame to
to check
                        for eviction.

====================================================================
Additions to the thread struct
/* Project 3 Additions */
    /* pagedir lock */
    struct lock pagedir_lock;
    /* spte table lock */
    struct lock spte_table_lock;
    /* Supplementary Page Table */
    struct hash spte_table;
    /* Next mapid_t to use */
    mapid_t mapid_counter;
    /* List of mmapped files */
    struct list mmapped_files;
====================================================================
---- ALGORITHMS ----
>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

The site struct tracks additional information for a page of user memory.

In this struct, we utilize several fields to track the location
of a page of memory.

First, the location filed indicates the location of the
page if it is not loaded into a frame of physical memory.
If we have a file page, we use the file*, and offset
fields to know where the page resides on disk. If we have
a swap location, we use the swap index to track the location
of the page in the swap space.

Finally, when the page is in physical memory, we also track
it with the struct frame* field, which points to the
struct frame that manages the physical memory location for where
that page resides. Thus, in order
to find the location of the data for a page, we first
check if the page is loaded via the is_loaded field. If true,
we consult the struct* frame to determine the location
of the data. Else, we consult the location external to physical
memory, as outlined above.

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

As mentioned in the section and the project spec, there is always
at least two memory mapping from virtual memory addresses to
physical memory, as the kernel and user virtual memory addresses
reference physical memory.

When checking the accessed and dirty bits for a page, we therefore
have to be aware of this aliasing issue. To avoid this problem, we always
check the bits for the user virtual address, but using the page_id in the
site struct, which is the page number (i.e. the rounded down version) of the
user virtual address.

Additionally, when implementing sharing further complicates this
matter. To implement sharing, we updated the struct frame
resident page field to be a list of site structs. Now, when checking
the accessed bits, we do so for each of the page_id fields in the
corresponding site structs, making sure to use the owner_thread
pagedir for each respective spte. If we find at least one that is set
we reset them all to 0, and move on. Else, if they are all 0, we update
the struct info for each site, and then evict the frame.
---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,

>> how are races avoided?

There are several major cases to consider. The first is the case
where the system is out of frames, and so we will need to evict
two frames to handle the requests. The second case is where
there is one frame remaining that is currently not being
used. In this case, we simply return the free
frame, and then evict an in use frame to handle the request.
The third case is where the system has two or more
free frames. In this case, we simply return two unique frames to
handle the request.

In each of these cases, race conditions can occur, because the
frames are global frames, and thus constitute a shared resource.
Thus, given multiple consumers of a shared resource, we have to ensure
that at any given time, only one of the consumers can consume,
so that the state of the shared resource is consistent, and that
if a consumer wants a shared resource and none are available
it takes appropriate action.

To do this, we use two different locks. The first is a global lock
called frame_evict_lock which acts as a protection mechanism around
the frame table. We acquire this lock to coordinate access to the frame
table. Specifically, during eviction, we can only have a single
thread operate the clock hand at a time. To enforce this
we acquire the frame_evict_lock before attempting eviction
to ensure that a single pass over the frame table is made
in each clock cycle.

The second lock, is actually many locks, but each serves the same
function. Specifically, we place a lock within each frame, to serve
as a synchronization mechanism on a frame struct that manages information
about a given frame of physical memory. Thus, a thread must
acquire the frame lock before writing or reading
information about physical frame of memory.

Note, as stated in the assignment spec, we also ensured that
our design allows for parallelism. Once a thread acquires the
frame lock for the frame it is going to consult, said thread
releases the frame_evict_lock, which allows other threads
to consult the frame table as needed.

---- RATIONALE ----
>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?


We designed both the spte and frame structs with two specifications
in mind. We wanted to ensure that we tracked all of the needed
state information for a given page or physical frame. We also wanted
to do it in as little space as possible, while ensuring proper
synchronization and readability.

In order to provide fast storage and fast lookup, we opted
to use a hash map to store the supplemental page
table for each thread. We initially considered a list, but the
list only offers fast insertion, as it requires iteration to
do extraction. The hash map required more code to write (hash
functions) but is better for performance.

We also opted to use an array of frame structs allocated in the kernel
to track the physical memory frames. We indexed the array to correspond
to the frame values returned by palloc to ensure consistency.
The reason we chose this data structure is that it allows for
ease during eviction. Using this array, the clock algorithm
used in eviction simply sweeps over the array by tracking an idea value of the
current frame to check. One potential criticism
of this design is that it allocates the array, even if
not all frames of physical memory are in use. We considered
this a worthwhile tradeoff over a list of frames that can shrink and grow,
or any other variable size data structure, which would significantly
complicate eviction.

                       PAGING TO AND FROM DISK
                       =======================
---- DATA STRUCTURES ----
>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
==================================================================
See above data structures, as they are used in paging as well.
==================================================================

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

Our eviction algorithm is based on the clock algorithm that
was covered in lecture. We manage a frame table, where each
index corresponds to a frame struct that manages info about

the corresponding physical frame of data.
We first acquire a frame_evict_lock to ensure that only one
thread at a time can access the frame table and update clock hand.
We then try to acquire the lock on the frame that the clock hand
currently points to. If we are unable to acquire the lock, we simply
move on, as this is more efficient for speed and prevents the system
from waiting on a single i/o intensive thread (parallelism mentioned
in the assignment).

If we acquire the frame lock, we check to make sure that the page
directory is not null, as on process exit, we set the page directory
to null. We then acquire the frame pagedir lock, to ensure that
we maintain consistent state across the read and writes of a threads
pagedir. Then, we check the access bits of page. We use the
user virtual address to avoid the aliasing issue. If accessed
we set to not accessed and move on. If not accessed, we
evict the page to its out of physical memory location, and clear the frame
site tracking relationships, and then return the clean frame.
Note, by implementing parallelism, we can use a while true
in the eviction so as to continually sweep until a frame frees
up. As discussed in OH, it is acceptable to break the sweep
process after a few passes, but this is a better solution because
a process should not exit due to inability to acquire a physical memory
location. It should wait until one opens up.

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

We update the frame->resident page pointer to point to the spte
struct for the new page that occupies the physical memory slot.
We update spte->frame to point to the struct frame for the
frame of physical memory in the spte of the page that was swapped in.
We update spte->frame to be null for the spte of the page
that was just swapped out. We then set the is_loaded field
to true and false in the swapped in and swapped out page
respectively.

We then take care to ensure that virtual address
translation is in tact. this constitutes clearing the
previous translation for the old page in the old process
and installing the new translation in the new process.
We do this by calling the functions clear_page and

install_page respectively.

In order to execute these translation updates, we need
to somehow determine what process a given page is associated with.
To do this, we store a pointer to the owner_thread in each spte.
This allows us update the address translations in the proper
process.

Finally, note that because the values in the spte and frame structs
are shared across multiple processes (i.e. the frame is global, and
the frame stores a pointer to the spte), we use locks around each
and only modify/read data after acquiring the necessary lock.



>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

As stated in OH and in the assignment, the stack must be restricted in size.
We are supposed to use a limit of 8 MB on stack size, which we check for.
Any access of memory that is not already mapped and is below this max stack
size is invalid.

If the address passes that first check, we next if the address is too high,
i.e. above PHYS_BASE. Again, if it is, this is invalid.
If this check passes, there are three possible valid stack accesses.

The first is a push instruction which will be 4 bytes below the stack pointer.
We check this location. If true, we assume a valid stack access and grow stack
as stated in assignment and OH.

The second is a pushA instruction, which is 32 bytes below the stack pointer.
We check this location. If true, we assume a valid stack access and grow the
stack
as stated in assignment and OH.

The third is an access that is above the stack. In this case, the stack
pointer
has been decremented, so we expand the stack, as stated in assignment spec
FAQ's.


---- SYNCHRONIZATION ----
>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

We use several locking mechanisms:

- global frame_evict_lock
- internal frame lock within each frame
- internal spte page lock within each spte
- lock around the pagedir of a thread
- lock around the thread specific spte table (This is
not needed per the assignment specifications, but we
plan on potentially extending to support multiple threads
in a process, in which case we would need the lock. Also
might be used to implement sharing. code commented
out, but left in place for potential future re-use).
Conditions for deadlock:

1. Limited Access to resources (mutual exclusion)
- We have this in this system, as explained in other
portions of this design doc. One approach to avoid this
is to split the resource into many copies where each consumer
has its own copy. This is inefficient from a memory standpoint as
it wastes space. Thus we largely avoid this.
One way in which we do this is by using a singe spte per page instead
of a global one. The global spte would have facilitated sharing,
but requires more synchronization as it is now a shared resource. (not
sure if you would like more explanation on this. In the interest
of brevity, will leave out. If desired, please contact Luke and he
will explain).

2. No Preemption:
- By virtualizing, we allow for the physical memory resources that
are shared by processes to be preemptible. Thus, this prevents the
case in which a single process is hogging the resource, and
preventing others from working. In our specific case, virtualizing
helps us to prevent deadlock in the case of the shared resource of
physical memory frames, as paging allows for pages to be swapped in
and out, and thus "preemptible." This is exactly as discussed in
lecture, and so I cite lecture here.

3. Multiple indepent requests for unique resources
- We have this condition in our design, as we have
multiple shared resources, the global fileystem lock, the
page frame edit lock, the frame table, the frame eructs, and
via pointers in the frame structs, the spte's. As stated
in lecture slides, one way to avoid deadlock in this case
is to wait on all resources at once. However, this is not
possible to do without knowing in advance the resources that
will be requested.

4. Circularity in graph of requests.
- Given that we have multiple independent resources that

are shared, this is our biggest issue. There are two
ways to overcome. The first is to use a system wide lock on resources.
This would prevent deadlock, but would severely hamper system
performance as only one process could proceed at a time. The other
solution is to ensure that there are no cycles by ensuring consistent
ordering of resource requests and releases. We do this in our design by
acquiring the lock on a single resource and then releasing the lock
as soon as we are finished with the resource, and then moving
on to the next resource. In the case where we need multiple
locks at once, we acquire and release in the same order, to
ensure no deadlock.


>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

There are two key steps in our design to ensure this. The first is
that we use the spte->page_id lock to ensure that at a given
page can only be evicted or loaded, but both cannot happen at the same
time.

The second issue we have to take care to address is the case where a page
is being evicted and written to at the same time. In order to prevent this,
before evicting a page, we clear the address translation before beginning the
eviction process. Thus, if the user tried to access said address of a
page getting evicted, the access would page fault, and the page fault
handler would have to wait on the page_id lock before it could
page back in. This lock is not released by evict until eviction is complete.
Thus, we are synchronized. Likewise, we only set a translation after the 
load of the page into physical memory is complete.

Thus, we ensure that Q cannot access or the modify the page during eviction
by clearing the address translation prior to beginning eviction. We avoid the 
race condition with our spte->page_lock, which a process must acquire
before beginning or finishing eviction. 


>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

This is where our frame lock comes in handy. We lock the frame 
when we are reading data into it, and unlock when finished. 
During eviction, a process can attempt to acquire a lock, but if
the attempt is failed, it moves on. Thus, it is not possible to
evict a page that is currently being read in via load function in our
code, as a result of the frame lock. 


>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

The first thing we do is we validate the pointers, as the assignment
instructs us to do. If the pointer is a valid user pointer, we then
pin the pages needed to execute the command. This is a two case process:
Case1: The page is already in a physical frame. In this case, we 
lock the frame. If, in the process of locking the frame, some other 
process came in and swapped us out, we check for this case, and if this is 
what happens, we restart the process from the top. If we acquire the frame
lock and we are still the page in the frame, then we have successfully pinned
Case 2: If we are not in a physical frame, we allocate a frame. This involves
acquiring the frame lock for the frame we will occupy (either via call to palloc, 
or call to evict frame). In the case of pinning, we do not want to release this
lock. This, we supply a special parameter is_pinning. If true we hold lock, else
release.

We call this pinning function for all pages that a system call will access. 

When the system call finishes, we simply call unpin, which releases these
frame locks.

The special case of strings passed to a system call to open a file is more involved.
In this case, we have to check the length of the string before we can proceed. Thus, 
while validating the string, we also pin in the process, and if we see an error, 
i.e. an invalid address or length exceeded, we unpin by reversing the process.


---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

Our design would fall on use of more locks than not in this continuum. This 
was primarily a product of our data structures and our desire to make evict frame
as parallel as possible. As a product of making evict parallel, we had to 
add locks to each frame, as opposed to a single global lock. This allows
for a process to work in a frame while another accesses the frame table. 

Furthermore, because we store spte srtuct in the frame, and the frame
is global, we have to use locks in the spte struct to coordinate this shared
access, and to coordinate the above synchronization issues involving load 
and eviction. 

We also use the pagedir lock out of necessity, as it is not
thread safe, as specified in OH, and because a process Q can
evict a process P's page, and thus call clear_page which 
accesses P's pagedir. 




                         MEMORY MAPPED FILES
                         ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Define the mapid_t type */
typedef int32_t mapid_t;

/* State keeping track of each mmapped file.
 * Note that multiple calls to mmap generate new mmap_states, even if the same
 * file was mmapped. */
struct mmap_state
{
    struct list_elem elem;  /* For the per-process list of mmapped files */
    struct file *fp;        /* The mmapped's owned reference to the file */
    void *vaddr;            /* Virtual address where the mmapped file begins */
    mapid_t mapping;        /* The per-process mapping id */
};

struct thread
{
    ...

    /* Next mapid_t to use */
    mapid_t mapid_counter;

    /* List of mmapped files */
    struct list mmapped_files;

    ...
}

Also relevant is the struct spte, (the supplementary page table entry), which
you can find in section A1.

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

In our supplementary page table, one of the types of spte we have is the
MMAPPED_PAGE type. This allows us to distinguish mmapped pages from other kinds
of pages, like swap pages and read-only file pages. When there is a page fault
attempting to read or write an mmapped page, we simply read the page in from
its location in the file, as determined by the spte that governs the particular
page. To evict an mmapped page, we simply check if it is dirty, and if so,
write it back to its location in the file as determined by the spte. Of course,
we are careful to keep track of the number of bytes that need to be read and
the number of bytes that must be zeroed, which we do in the spte.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

Each virtual page owned by a user process is associated with an spte, and for
each process, we keep track of all spte's in the per-thread spte_table. Thus,
to make sure that the new file mapping does not overlap with any existing
segment, we check all of the page addresses that we'd need for the mmap to see
 if they are in our spte table, (that is, already used by the process for some
other reason). Since the spte table is a hash table, this takes time linear in
the number of pages that the mmap would need. Only after this check do we
complete the mmap by adding the new mmap spte's to the process's spte_table.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

We do share some of the same implementations. For loading an mmap page into
physical memory, or for loading an executable page from memory, in both cases
we simply need to take the page from its location in the particular file and
then copy it into the memory buffer. So we use the same code for this. However,
we do not write executable pages back to disk, or stack pages to disk, so we
needed to write a new function for evicting mmapped pages, rather than sharing
the implementation with some other type of page.


                           SURVEY QUESTIONS
                           ================
Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.
>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?
>> Did you find that working on a particular part of the assignment gave

>> you greater insight into some aspect of OS design?
>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?
>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?
>> Any other comments?
